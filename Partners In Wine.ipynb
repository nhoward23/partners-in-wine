{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partners in Wine\n",
    "\n",
    "<img src=\"wine.png\" width=\"400\" height=\"500\">\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### What is the dataset?\n",
    "This dataset is various attributes describing the chemical makeup of the wine Portuguese \"Vinho Verde\" wine. for varying seasons.  \n",
    "\n",
    "fixed acidity;volatile acidity;citric acid;residual sugar;chlorides;free sulfur dioxide;total sulfur dioxide;density;pH;sulphates;alcohol;quality\n",
    "\n",
    "### What will we do with this dataset?\n",
    "Perform some stuff to discover stuff about the data. First we need to read the file with all the data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "table = utils.read_table('red_wine_quality.csv')\n",
    "header = table[0]\n",
    "table = table[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "\n",
    "### K-Means Clustering \n",
    "\n",
    "We can use k-means clustering to determine what attributes make for a high quality wine. K-means clustering groups up instances that are closest to eachother with k groups. This image is an example:\n",
    "\n",
    "<img src=\"cluster.png\" width=\"400\" height=\"500\">\n",
    "\n",
    "The code below is used to find the best k for our dataset. We are going to try k=3 to k=10. We will plot the objective function scores in order to find the \"elbow\" point, the point at which the total sum of squares drops less drastically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "20109.461284475514\n",
      "4\n",
      "17429.51220694328\n",
      "5\n",
      "15022.907290461892\n",
      "6\n",
      "13449.400493270117\n",
      "7\n",
      "12956.629842388129\n",
      "8\n",
      "12017.666899775344\n",
      "9\n",
      "11415.713148442654\n",
      "10\n",
      "10972.850957097786\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "import copy\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import k_means\n",
    "\n",
    "def k_means_clustering(k, table):\n",
    "    # Select k objects in an arbitrary fashion. Use these as the initial set of k centroids.\n",
    "    centroids = k_means.select_init_centroids(k, table)\n",
    "    \n",
    "    match = False\n",
    "    while match == False: \n",
    "        \n",
    "        # Compute the distances of each instance to each centroid\n",
    "        distances_table = [ [] for i in range(len(table)) ]\n",
    "        for centroid in centroids:\n",
    "            k_means.append_distance(table, distances_table, centroid)\n",
    "\n",
    "        # Find the biggest distance and assign instance to that centroid\n",
    "        k_means.find_centroid(distances_table)\n",
    "\n",
    "        # Recalculate the centroids by getting the mean of each cluster\n",
    "        new_centroids = k_means.recalculate_centroids(table, distances_table, [])\n",
    "\n",
    "        # Check to see if the centroids have converged\n",
    "        match = k_means.compare_centroids(centroids, new_centroids)\n",
    "        centroids = new_centroids\n",
    "\n",
    "    # Now we know what instance belongs to what cluster\n",
    "    # table and distances are \"parallel tables\" \n",
    "    score = objective_function(table, distances_table, centroids)\n",
    "    return score, distances_table, centroids\n",
    "    \n",
    "def objective_function(table, cluster_table, centroids):\n",
    "    # Combine and group by cluster \n",
    "    new_table = k_means.combine_tables(table, cluster_table)\n",
    "    cluster_index = len(new_table[0])-1\n",
    "    group_names, groups = utils.group_by(new_table, cluster_index)\n",
    "    \n",
    "    # for each cluster, compute the sum of squares\n",
    "    # add these to a cluster_total of all clusters\n",
    "    total_cluster_score = 0\n",
    "    for i, cluster in enumerate(groups):\n",
    "        distances = []\n",
    "        for row in cluster:\n",
    "            distance = k_means.compute_distance(row, centroids[row[cluster_index]])\n",
    "            distances.append(distance)\n",
    "        total_cluster_score += sum(distances)\n",
    "    print(total_cluster_score)\n",
    "    return total_cluster_score\n",
    "        \n",
    "def find_best_cluster(table, minimum, maximum):\n",
    "    objective_scores = []\n",
    "    x_axis = []\n",
    "    for i in range(minimum, maximum+1):\n",
    "        print(i)\n",
    "        score, cluster_table, centroids = k_means_clustering(i, table)\n",
    "        objective_scores.append(score)\n",
    "        x_axis.append(i)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(x_axis, objective_scores)\n",
    "    plt.show()\n",
    "\n",
    "# find the best k for clustering from 3-10.\n",
    "find_best_cluster(table, 3, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best K is 6! \n",
    "\n",
    "Each time this runs, the values change a little bit but it is roughly the same output everytime. The elbow point appears to be around 6 or 7 everytime. We will choose to use 6 clusters. \n",
    "\n",
    "Now that we have found the best number of clusters, we can use them to learn more information about our dataset. We can also predict unseen instances. We do this by finding what cluster the unseen instance belongs to and then doing majority voting on that cluster to classify the instance's quality rating. \n",
    "\n",
    "First, we will look at the cluster and see what we can find out by observing the averages of each attribute for each cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13449.40049327012\n",
      "============================================================\n",
      "Cluster 1:\n",
      "============================================================\n",
      "Most Frequent Classification:  5.0\n",
      "\n",
      "Averages for Each Attribute \n",
      "fixed acidity:  8.06\n",
      "volatile acidity:  0.56\n",
      "citric acid:  0.32\n",
      "residual sugar:  3.45\n",
      "chlorides:  0.09\n",
      "free sulfur dioxide:  32.28\n",
      "total sulfur dioxide:  139.06\n",
      "density:  1.0\n",
      "pH:  3.23\n",
      "sulphates:  0.7\n",
      "alcohol:  9.8\n",
      "quality:  5.13\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Cluster 2:\n",
      "============================================================\n",
      "Most Frequent Classification:  6.0\n",
      "\n",
      "Averages for Each Attribute \n",
      "fixed acidity:  8.35\n",
      "volatile acidity:  0.52\n",
      "citric acid:  0.26\n",
      "residual sugar:  2.48\n",
      "chlorides:  0.09\n",
      "free sulfur dioxide:  18.3\n",
      "total sulfur dioxide:  45.16\n",
      "density:  1.0\n",
      "pH:  3.32\n",
      "sulphates:  0.67\n",
      "alcohol:  10.45\n",
      "quality:  5.7\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Cluster 3:\n",
      "============================================================\n",
      "Most Frequent Classification:  5.0\n",
      "\n",
      "Averages for Each Attribute \n",
      "fixed acidity:  8.15\n",
      "volatile acidity:  0.52\n",
      "citric acid:  0.28\n",
      "residual sugar:  2.48\n",
      "chlorides:  0.09\n",
      "free sulfur dioxide:  25.55\n",
      "total sulfur dioxide:  65.09\n",
      "density:  1.0\n",
      "pH:  3.33\n",
      "sulphates:  0.68\n",
      "alcohol:  10.27\n",
      "quality:  5.55\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Cluster 4:\n",
      "============================================================\n",
      "Most Frequent Classification:  6.0\n",
      "\n",
      "Averages for Each Attribute \n",
      "fixed acidity:  8.67\n",
      "volatile acidity:  0.51\n",
      "citric acid:  0.3\n",
      "residual sugar:  2.51\n",
      "chlorides:  0.09\n",
      "free sulfur dioxide:  6.08\n",
      "total sulfur dioxide:  15.15\n",
      "density:  1.0\n",
      "pH:  3.3\n",
      "sulphates:  0.64\n",
      "alcohol:  10.72\n",
      "quality:  5.76\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Cluster 5:\n",
      "============================================================\n",
      "Most Frequent Classification:  5.0\n",
      "\n",
      "Averages for Each Attribute \n",
      "fixed acidity:  7.8\n",
      "volatile acidity:  0.58\n",
      "citric acid:  0.26\n",
      "residual sugar:  3.1\n",
      "chlorides:  0.09\n",
      "free sulfur dioxide:  23.2\n",
      "total sulfur dioxide:  95.5\n",
      "density:  1.0\n",
      "pH:  3.31\n",
      "sulphates:  0.64\n",
      "alcohol:  10.09\n",
      "quality:  5.39\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Cluster 6:\n",
      "============================================================\n",
      "Most Frequent Classification:  6.0\n",
      "\n",
      "Averages for Each Attribute \n",
      "fixed acidity:  8.32\n",
      "volatile acidity:  0.53\n",
      "citric acid:  0.25\n",
      "residual sugar:  2.22\n",
      "chlorides:  0.08\n",
      "free sulfur dioxide:  11.6\n",
      "total sulfur dioxide:  28.85\n",
      "density:  1.0\n",
      "pH:  3.32\n",
      "sulphates:  0.65\n",
      "alcohol:  10.45\n",
      "quality:  5.72\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cluster the dataset to form 6 groups \n",
    "score, distances_table, centroids = k_means_clustering(6, table)\n",
    "\n",
    "# create a cluster table\n",
    "cluster_table = copy.deepcopy(table)\n",
    "for i, row in enumerate(cluster_table):\n",
    "    cluster_table[i].append(distances_table[i][-1])\n",
    "\n",
    "# group by cluster \n",
    "group_names, groups = utils.group_by(cluster_table, len(cluster_table[0])-1)\n",
    "\n",
    "# for each cluster, let's find out some stuff.\n",
    "for i, group in enumerate(groups):\n",
    "    values, counts = utils.get_frequencies(group, header.index(\"quality\"))\n",
    "    avg_att_vals = k_means.compute_average(group, len(group[0])-1)\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Cluster \" + str(i+1) + \":\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # get the most frequently occuring quality classification\n",
    "    most_freq_qual_index = counts.index(max(counts))\n",
    "    most_freq_quality = values[most_freq_qual_index]\n",
    "    print(\"Most Frequent Classification: \", most_freq_quality)\n",
    "    print()\n",
    "    \n",
    "    # print the average for each attribute\n",
    "    print(\"Averages for Each Attribute \")\n",
    "    for i, attribute in enumerate(avg_att_vals):\n",
    "        print(header[i] + \": \", attribute)\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What can we take away? \n",
    "\n",
    "By observing the averages for each attribute in each cluster, we have discovered some attributes that vary. We noticed that the clusters with the most classifications of a quality 6 have some attributes that vary from clusters that are mostly a 5 rating. \n",
    "\n",
    "6 rating has:\n",
    "slightly higher fixed acidity\n",
    "a lower residual sugar\n",
    "a lower free sulfur dioxide\n",
    "a lower total sulfur dioxide\n",
    "\n",
    "We can inform the vineyard of this information and to carefully monitor these properties because it appears to have an affect on the quality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Results\n",
    "\n",
    "\n",
    "## Random Subsampling with K-means-clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.9, 0.22, 0.48, 1.8, 0.077, 29, 60, 0.9968, 3.39, 0.53, 9.4, 6]\n",
      "5.0\n",
      "============================================================================\n",
      "Predictive Accuracy of K-Means Clustering with Random Subsampling\n",
      "============================================================================\n",
      "Accuracy = 0.83, error rate = 0.17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predicting\n",
    "random_instance = [8.9,0.22,0.48,1.8,0.077,29,60,0.9968,3.39,0.53,9.4,6]\n",
    "classification = k_means.predict(random_instance, centroids, groups, header.index(\"quality\"))\n",
    "print(random_instance)\n",
    "print(classification)\n",
    "\n",
    "\n",
    "#random subsampling \n",
    "random_avg_accuracy, random_stderr = k_means.random_subsampling(5, table, header.index(\"quality\"), centroids, groups)\n",
    "print(\"=\" * 76)\n",
    "print(\"Predictive Accuracy of K-Means Clustering with Random Subsampling\")\n",
    "print(\"=\" * 76)\n",
    "print(\"Accuracy = %0.2f, error rate = %0.2f\" %(random_avg_accuracy, random_stderr))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Sampling with Naive Bayes\n",
    "\n",
    "We can change up the attributes we choose to see what has more predictive accuracy. Since we discerned that the fixed acidity, residual sugar, free sulfur dioxide, and total sulfur dioxide may result in a higher quality one, we can test these out with our naive bayes classifier. \n",
    "\n",
    "We also will test some other attributes, including residual sugar, density, and alcohol. We believe that college students will be more concerned with these attributes so we want to see what will be predicted by using these attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================\n",
      "STEP 3: Predictive Accuracy of Naive Bayes with Guassian\n",
      "============================================================================\n",
      "Random Subsample (k=10, 2:1 Train/Test)\n",
      "Naive Bayes: accuracy = 0.82, error rate = 0.18\n",
      "\n",
      "============================================================================\n",
      "STEP 3: Predictive Accuracy of Naive Bayes with Guassian\n",
      "============================================================================\n",
      "Random Subsample (k=10, 2:1 Train/Test)\n",
      "Naive Bayes: accuracy = 0.84, error rate = 0.16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import naive_bayes\n",
    "\n",
    "# we noticed these attributes vary with K-means so lets see \n",
    "indices = [header.index(\"fixed acidity\"),header.index('residual sugar'),header.index('free sulfur dioxide'), header.index('total sulfur dioxide')]\n",
    "#['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide',\n",
    "#'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n",
    "\n",
    "# Random SubSampling with Naive Bayes\n",
    "random_avg_accuracy, random_stderr = naive_bayes.random_subsampling(5, table, header.index(\"quality\"), indices)\n",
    "print(\"=\" * 76)\n",
    "print(\"STEP 3: Predictive Accuracy of Naive Bayes with Guassian\")\n",
    "print(\"=\" * 76)\n",
    "print(\"Random Subsample (k=10, 2:1 Train/Test)\")\n",
    "print(\"Naive Bayes: accuracy = %0.2f, error rate = %0.2f\" %(random_avg_accuracy, random_stderr))\n",
    "print()\n",
    "\n",
    "\n",
    "# college students care about these\n",
    "indices = [header.index('residual sugar'),header.index('density'), header.index('alcohol')]\n",
    "\n",
    "\n",
    "# Random SubSampling with Naive Bayes\n",
    "random_avg_accuracy, random_stderr = naive_bayes.random_subsampling(5, table, header.index(\"quality\"), indices)\n",
    "print(\"=\" * 76)\n",
    "print(\"STEP 3: Predictive Accuracy of Naive Bayes with Guassian\")\n",
    "print(\"=\" * 76)\n",
    "print(\"Random Subsample (k=10, 2:1 Train/Test)\")\n",
    "print(\"Naive Bayes: accuracy = %0.2f, error rate = %0.2f\" %(random_avg_accuracy, random_stderr))\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
