{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partners in Wine\n",
    "\n",
    "<img src=\"wine.png\" width=\"400\" height=\"500\">\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Introduction: This section must briefly describe the dataset you used and the classification task you implemented (e.g., what were you trying to classify in the dataset). You should also briefly describe your findings (e.g., what classifier approach performed the best).\n",
    "\n",
    "### What is the dataset?\n",
    "This dataset is various attributes describing the makeup of the wine Portuguese \"Vinho Verde\" wine. The classification is a rating from 1-10 to decribe the quality of the wine. \n",
    "\n",
    "\n",
    "### What will we do with this dataset?\n",
    "This section must briefly describe the dataset you used and the classification task you implemented (e.g., what were you trying to classify in the dataset). You should also briefly describe your findings (e.g., what classifier approach performed the best).\n",
    "\n",
    "We used KNN, Naive Bayes, K-means clustering, and KNN-Bagging Ensemble classifiers on our dataset. We use these to predict the quality of a wine based on various attributes of our choosing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "table = utils.read_table('red_wine_quality.csv')\n",
    "header = table[0]\n",
    "table = table[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "Data Analysis: This section must provide details about the dataset. You must include:\n",
    "Information about the dataset itself, e.g., the attributes and attribute types, the number of instances, and the attribute being used as the label.\n",
    "Relevant summary statistics about the dataset.\n",
    "Data visualizations highlighting important/interesting aspects of your dataset. Visualizations may include frequency distributions, comparisons of attributes (scatterplot, multiple frequency diagrams), box and whisker plots, etc. The goal is not to include all possible diagrams, but instead to select and highlight diagrams that provide insight about the dataset itself.\n",
    "Note that this section must describe the above (in paragraph form) and not just provide diagrams and statistics. Also, each figure included must have a figure caption (Figure number and textual description) that is referenced from the text (e.g., “Figure 2 shows a frequency diagram for ...”).\n",
    "\n",
    "\n",
    "### About the Dataset\n",
    "\n",
    "The dataset has approximately 1600 instances. There are 12 attributes and they are all continuous. They are floats. The attribute being used as the label is the quality attribute. It is ranked on a scale from 1-10. [View the dataset here](https://archive.ics.uci.edu/ml/datasets/wine+quality). \n",
    "\n",
    "The attributes are:\n",
    "- fixed acidity\n",
    "- volatile acidity\n",
    "- citric acid\n",
    "- residual sugar\n",
    "- chlorides \n",
    "- free sulfur dioxide \n",
    "- total sulfur dioxide\n",
    "- density \n",
    "- pH\n",
    "- sulfates\n",
    "- alcohol\n",
    "- **quality**\n",
    "\n",
    "### Summary Statistics and Data Visualization\n",
    "\n",
    "Since we aren't oenologists , we don't really know much about these attributes and their relations. Since we really only care about how it relates to the quality, we will perform K-means clustering to analyze the data. We will cluster them and see what the majority classification is for that cluster. Then, we will get the average of each attribute and see if we can spot any differences between these clusters. \n",
    "\n",
    "However, before we do that, it is important to view the distribution of our classifications. This will give us an insight in our future classification predictions. \n",
    "\n",
    "#### No. of quality ratings:\n",
    "As you can see in Figure 1, the majority of the dataset is classified as either a 5 or 6. There are some 3's, 7's, and 8's but no 9 or 10. This distribution is important to be aware of when we start our classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "values, counts = utils.get_frequencies(table, header.index('quality'))\n",
    "plt.figure()\n",
    "plt.bar(values, counts)\n",
    "plt.title(\"Figure 1.\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Means Clustering to help with Data Analysis \n",
    "\n",
    "We can use k-means clustering to determine what attributes make for a high quality wine. K-means clustering groups up instances that are closest to eachother with k groups. This image is an example:\n",
    "\n",
    "<img src=\"cluster.png\" width=\"400\" height=\"500\">\n",
    "\n",
    "The code below is used to find the best k for our dataset. We are going to try k=3 to k=10. We will plot the objective function scores in order to find the \"elbow\" point, the point at which the total sum of squares drops less drastically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "20109.461284475514\n",
      "4\n",
      "17360.11819202622\n",
      "5\n",
      "15022.907290461892\n",
      "6\n",
      "13449.40049327012\n",
      "7\n",
      "12606.12490152986\n",
      "8\n",
      "12017.666899775346\n",
      "9\n",
      "11415.713148442654\n",
      "10\n",
      "10957.855783653677\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "import copy\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import k_means\n",
    "\n",
    "def k_means_clustering(k, table):\n",
    "    # Select k objects in an arbitrary fashion. Use these as the initial set of k centroids.\n",
    "    centroids = k_means.select_init_centroids(k, table)\n",
    "    \n",
    "    match = False\n",
    "    while match == False: \n",
    "        \n",
    "        # Compute the distances of each instance to each centroid\n",
    "        distances_table = [ [] for i in range(len(table)) ]\n",
    "        for centroid in centroids:\n",
    "            k_means.append_distance(table, distances_table, centroid)\n",
    "\n",
    "        # Find the biggest distance and assign instance to that centroid\n",
    "        k_means.find_centroid(distances_table)\n",
    "\n",
    "        # Recalculate the centroids by getting the mean of each cluster\n",
    "        new_centroids = k_means.recalculate_centroids(table, distances_table, [])\n",
    "\n",
    "        # Check to see if the centroids have converged\n",
    "        match = k_means.compare_centroids(centroids, new_centroids)\n",
    "        centroids = new_centroids\n",
    "\n",
    "    # Now we know what instance belongs to what cluster\n",
    "    # table and distances are \"parallel tables\" \n",
    "    score = objective_function(table, distances_table, centroids)\n",
    "    return score, distances_table, centroids\n",
    "    \n",
    "def objective_function(table, cluster_table, centroids):\n",
    "    # Combine and group by cluster \n",
    "    new_table = k_means.combine_tables(table, cluster_table)\n",
    "    cluster_index = len(new_table[0])-1\n",
    "    group_names, groups = utils.group_by(new_table, cluster_index)\n",
    "    \n",
    "    # for each cluster, compute the sum of squares\n",
    "    # add these to a cluster_total of all clusters\n",
    "    total_cluster_score = 0\n",
    "    for i, cluster in enumerate(groups):\n",
    "        distances = []\n",
    "        for row in cluster:\n",
    "            distance = k_means.compute_distance(row, centroids[row[cluster_index]])\n",
    "            distances.append(distance)\n",
    "        total_cluster_score += sum(distances)\n",
    "    print(total_cluster_score)\n",
    "    return total_cluster_score\n",
    "        \n",
    "def find_best_cluster(table, minimum, maximum):\n",
    "    objective_scores = []\n",
    "    x_axis = []\n",
    "    for i in range(minimum, maximum+1):\n",
    "        print(i)\n",
    "        score, cluster_table, centroids = k_means_clustering(i, table)\n",
    "        objective_scores.append(score)\n",
    "        x_axis.append(i)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(\"Figure 2.\")\n",
    "    plt.plot(x_axis, objective_scores)\n",
    "    plt.show()\n",
    "\n",
    "# find the best k for clustering from 3-10.\n",
    "find_best_cluster(table, 3, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best K is 6! \n",
    "\n",
    "Each time this runs, the values change a little bit but it is roughly the same output everytime. The elbow point appears to be around 6 or 7 everytime, as you can see in Figure 2. We will choose to use 6 clusters. \n",
    "\n",
    "Now that we have found the best number of clusters, we can use them to learn more information about our dataset. \n",
    "We will look at the cluster and see what we can find out by observing the averages of each attribute for each cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13449.40049327012\n",
      "============================================================\n",
      "Cluster 1:\n",
      "============================================================\n",
      "Most Frequent Classification:  6.0\n",
      "\n",
      "Averages for Each Attribute \n",
      "fixed acidity:  8.32\n",
      "volatile acidity:  0.53\n",
      "citric acid:  0.25\n",
      "residual sugar:  2.22\n",
      "chlorides:  0.08\n",
      "free sulfur dioxide:  11.6\n",
      "total sulfur dioxide:  28.85\n",
      "density:  1.0\n",
      "pH:  3.32\n",
      "sulphates:  0.65\n",
      "alcohol:  10.45\n",
      "quality:  5.72\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Cluster 2:\n",
      "============================================================\n",
      "Most Frequent Classification:  6.0\n",
      "\n",
      "Averages for Each Attribute \n",
      "fixed acidity:  8.67\n",
      "volatile acidity:  0.51\n",
      "citric acid:  0.3\n",
      "residual sugar:  2.51\n",
      "chlorides:  0.09\n",
      "free sulfur dioxide:  6.08\n",
      "total sulfur dioxide:  15.15\n",
      "density:  1.0\n",
      "pH:  3.3\n",
      "sulphates:  0.64\n",
      "alcohol:  10.72\n",
      "quality:  5.76\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Cluster 3:\n",
      "============================================================\n",
      "Most Frequent Classification:  6.0\n",
      "\n",
      "Averages for Each Attribute \n",
      "fixed acidity:  8.35\n",
      "volatile acidity:  0.52\n",
      "citric acid:  0.26\n",
      "residual sugar:  2.48\n",
      "chlorides:  0.09\n",
      "free sulfur dioxide:  18.3\n",
      "total sulfur dioxide:  45.16\n",
      "density:  1.0\n",
      "pH:  3.32\n",
      "sulphates:  0.67\n",
      "alcohol:  10.45\n",
      "quality:  5.7\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Cluster 4:\n",
      "============================================================\n",
      "Most Frequent Classification:  5.0\n",
      "\n",
      "Averages for Each Attribute \n",
      "fixed acidity:  8.06\n",
      "volatile acidity:  0.56\n",
      "citric acid:  0.32\n",
      "residual sugar:  3.45\n",
      "chlorides:  0.09\n",
      "free sulfur dioxide:  32.28\n",
      "total sulfur dioxide:  139.06\n",
      "density:  1.0\n",
      "pH:  3.23\n",
      "sulphates:  0.7\n",
      "alcohol:  9.8\n",
      "quality:  5.13\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Cluster 5:\n",
      "============================================================\n",
      "Most Frequent Classification:  5.0\n",
      "\n",
      "Averages for Each Attribute \n",
      "fixed acidity:  8.15\n",
      "volatile acidity:  0.52\n",
      "citric acid:  0.28\n",
      "residual sugar:  2.48\n",
      "chlorides:  0.09\n",
      "free sulfur dioxide:  25.55\n",
      "total sulfur dioxide:  65.09\n",
      "density:  1.0\n",
      "pH:  3.33\n",
      "sulphates:  0.68\n",
      "alcohol:  10.27\n",
      "quality:  5.55\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Cluster 6:\n",
      "============================================================\n",
      "Most Frequent Classification:  5.0\n",
      "\n",
      "Averages for Each Attribute \n",
      "fixed acidity:  7.8\n",
      "volatile acidity:  0.58\n",
      "citric acid:  0.26\n",
      "residual sugar:  3.1\n",
      "chlorides:  0.09\n",
      "free sulfur dioxide:  23.2\n",
      "total sulfur dioxide:  95.5\n",
      "density:  1.0\n",
      "pH:  3.31\n",
      "sulphates:  0.64\n",
      "alcohol:  10.09\n",
      "quality:  5.39\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cluster the dataset to form 6 groups \n",
    "score, distances_table, centroids = k_means_clustering(6, table)\n",
    "\n",
    "# create a cluster table\n",
    "cluster_table = copy.deepcopy(table)\n",
    "for i, row in enumerate(cluster_table):\n",
    "    cluster_table[i].append(distances_table[i][-1])\n",
    "\n",
    "# group by cluster \n",
    "group_names, groups = utils.group_by(cluster_table, len(cluster_table[0])-1)\n",
    "\n",
    "# for each cluster, let's find out some stuff.\n",
    "for i, group in enumerate(groups):\n",
    "    values, counts = utils.get_frequencies(group, header.index(\"quality\"))\n",
    "    avg_att_vals = k_means.compute_average(group, len(group[0])-1)\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Cluster \" + str(i+1) + \":\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # get the most frequently occuring quality classification\n",
    "    most_freq_qual_index = counts.index(max(counts))\n",
    "    most_freq_quality = values[most_freq_qual_index]\n",
    "    print(\"Most Frequent Classification: \", most_freq_quality)\n",
    "    print()\n",
    "    \n",
    "    # print the average for each attribute\n",
    "    print(\"Averages for Each Attribute \")\n",
    "    for i, attribute in enumerate(avg_att_vals):\n",
    "        print(header[i] + \": \", attribute)\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can we take away? \n",
    "\n",
    "By observing the averages for each attribute in each cluster, we have discovered some attributes that vary. We noticed that the clusters with the most classifications of a quality 6 have some attributes that vary from clusters that are mostly a 5 rating. \n",
    "\n",
    "Classification 6 has:\n",
    "- a slightly higher fixed acidity\n",
    "- a lower residual sugar\n",
    "- a lower free sulfur dioxide\n",
    "- a lower total sulfur dioxide\n",
    "\n",
    "We can inform the vineyard of this information and to carefully monitor these properties because it appears to have an affect on the quality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Results\n",
    "\n",
    "\n",
    "## Random Subsampling with K-Means Clustering\n",
    "We used the centroids and clusters we created above to make predictions on random instances. We did this by taking random instances and finding what centroid it is closest to. Then, we find the majority class label of that cluster with majority voting. We tested our classifier by using random subsampling. For k times, we create a new training set and recalculated the centroids and clusters. Then we predict all the instances in the test set and compute the accuracy. You can see below that this classifier has a predictive accuracy of 83%. This is a high-performing classifier. I think that this is a high performer because most often the majority class of a cluster will be a 5 or 6. Since most of the instances in our dataset have a quality rating of 5 or 6 it will predict correctly for instances a good number of times. Below we run the k_means clustering with random subsampling and show its accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================\n",
      "Predictive Accuracy of K-Means Clustering with Random Subsampling\n",
      "============================================================================\n",
      "Accuracy = 0.83, error rate = 0.17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#random subsampling \n",
    "random_avg_accuracy, random_stderr = k_means.random_subsampling(5, table, header.index(\"quality\"), centroids, groups)\n",
    "print(\"=\" * 76)\n",
    "print(\"Predictive Accuracy of K-Means Clustering with Random Subsampling\")\n",
    "print(\"=\" * 76)\n",
    "print(\"Accuracy = %0.2f, error rate = %0.2f\" %(random_avg_accuracy, random_stderr))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes with Random Subsampling\n",
    "The next classifier we used is Naive Bayes. This classifier uses prior and posterior probabilities and selects the classification with the highest probability to predict the label for each instance. It was designed to take in a list of indicies to include as posterior probabilities. We tested the classifier's predictive ability by using random subsampling. With this testing method, it has an accuracy of around 80%, fluctuating depending on what attributes you choose. \n",
    "\n",
    "Since we discerned that the fixed acidity, residual sugar, free sulfur dioxide, and total sulfur dioxide may result in a higher quality wine, we can test these out with our naive bayes classifier to see these attributes are more predictive of the quality of wine. The results show that the accuracy with these attributes are 81%. \n",
    "\n",
    "We also will test some other attributes, including residual sugar, density, and alcohol. We believe that college students will be more concerned with these attributes so we want to see what will be predicted by using these attributes. The results show that using Naive Bayes with these attributes results in an accuracy of 84%. \n",
    "\n",
    "While the second set of attributes had the highest accuracy, both are in the 80 percentile which is high. Like the classifier above it predicts 5 or 6 most of the time because the majority of the dataset is classified as 5 or 6 so the predictive accuracy is high. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================\n",
      "Predictive Accuracy of Naive Bayes with Guassian\n",
      "============================================================================\n",
      "Random Subsample (k=10, 2:1 Train/Test)\n",
      "Naive Bayes: accuracy = 0.81, error rate = 0.19\n",
      "\n",
      "============================================================================\n",
      "Predictive Accuracy of Naive Bayes with Guassian\n",
      "============================================================================\n",
      "Random Subsample (k=10, 2:1 Train/Test)\n",
      "Naive Bayes: accuracy = 0.84, error rate = 0.16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import naive_bayes\n",
    "\n",
    "# we noticed these attributes vary with K-means so lets see \n",
    "indices = [header.index(\"fixed acidity\"),header.index('residual sugar'),header.index('free sulfur dioxide'), header.index('total sulfur dioxide')]\n",
    "#['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide',\n",
    "#'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n",
    "\n",
    "# Random SubSampling with Naive Bayes\n",
    "random_avg_accuracy, random_stderr = naive_bayes.random_subsampling(5, table, header.index(\"quality\"), indices)\n",
    "print(\"=\" * 76)\n",
    "print(\"Predictive Accuracy of Naive Bayes with Guassian\")\n",
    "print(\"=\" * 76)\n",
    "print(\"Random Subsample (k=10, 2:1 Train/Test)\")\n",
    "print(\"Naive Bayes: accuracy = %0.2f, error rate = %0.2f\" %(random_avg_accuracy, random_stderr))\n",
    "print()\n",
    "\n",
    "\n",
    "# college students care about these\n",
    "indices = [header.index('residual sugar'),header.index('density'), header.index('alcohol')]\n",
    "\n",
    "\n",
    "# Random SubSampling with Naive Bayes\n",
    "random_avg_accuracy, random_stderr = naive_bayes.random_subsampling(5, table, header.index(\"quality\"), indices)\n",
    "print(\"=\" * 76)\n",
    "print(\"Predictive Accuracy of Naive Bayes with Guassian\")\n",
    "print(\"=\" * 76)\n",
    "print(\"Random Subsample (k=10, 2:1 Train/Test)\")\n",
    "print(\"Naive Bayes: accuracy = %0.2f, error rate = %0.2f\" %(random_avg_accuracy, random_stderr))\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
